# ‚ö° KernelPyTorch

**Production-grade PyTorch GPU optimization framework for 2-5x performance improvements.**

[![Tests](https://img.shields.io/badge/tests-477%20passing-brightgreen)](./BENCHMARKS.md) [![Demos](https://img.shields.io/badge/demos-11%20working-blue)](./demos/) [![Python](https://img.shields.io/badge/python-3.9%2B-blue)](https://python.org) [![PyTorch](https://img.shields.io/badge/pytorch-2.0%2B-orange)](https://pytorch.org)

## üöÄ What is KernelPyTorch?

KernelPyTorch is a **high-performance optimization framework** that accelerates PyTorch models through:

- **üéØ Advanced Attention**: Million-token sequences, 90% compute reduction, multi-GPU coordination
- **‚ö° Dynamic Shape Bucketing**: 3x speedup on variable-size inputs with intelligent padding
- **üî• FP8 Training**: 2x speedup on H100/Blackwell with maintained accuracy
- **üîß Hardware Abstraction**: Unified optimization for NVIDIA, AMD, Intel GPUs
- **üöÄ Neural Operator Fusion**: 40-60% kernel overhead reduction with single-kernel attention+FFN fusion
- **üé® Adaptive Precision**: 30% quality improvement through entropy-based precision allocation
- **üß™ Production Ready**: 477+ tests, 11 demos, comprehensive benchmarks

## ‚è±Ô∏è Quick Start (2 minutes)

### **Installation**
```bash
git clone <repository-url>
cd shahmod
pip install -r requirements.txt

# Verify installation
python -c "import kernel_pytorch; print('‚úÖ KernelPyTorch ready!')"
```

### **Basic Usage**
```python
import torch
from kernel_pytorch.attention import create_ring_attention
from kernel_pytorch.precision import create_fp8_trainer

# Million-token sequences with linear memory
attention = create_ring_attention(d_model=512, num_heads=8, max_sequence_length=1_000_000)
output = attention(long_sequence)  # O(N) memory vs O(N¬≤)

# 3x faster variable inputs with dynamic shape bucketing
from kernel_pytorch.optimization_patterns import DynamicShapeModule, create_optimal_bucketing_system
bucketing = create_optimal_bucketing_system(sample_inputs)
optimized_model = DynamicShapeModule(model, bucketing)  # 3x speedup

# 2x faster training on H100
trainer = create_fp8_trainer(model)
with trainer:
    loss = trainer.training_step(inputs, targets)  # 2x speedup

# 40-60% kernel overhead reduction with Neural Operator Fusion
from kernel_pytorch.attention import create_unified_attention_fusion
fused_model = create_unified_attention_fusion(transformer_model)  # Single-kernel execution

# 30% quality improvement with Adaptive Precision Allocation
from kernel_pytorch.precision import create_ultra_precision_module
adaptive_model = create_ultra_precision_module(model)  # Entropy-based precision
```

### **Quick Validation**
```bash
# Run demos (2-3 minutes)
PYTHONPATH=../src python demos/run_all_demos.py --quick

# Run benchmarks (5-10 minutes)
PYTHONPATH=src python benchmarks/run_comprehensive_benchmark.py --quick

# Run tests (1-2 minutes)
PYTHONPATH=src python -m pytest tests/ --tb=short
```

## üéØ Key Features

### **üî• Advanced Attention Mechanisms**

#### **Ring Attention - Million Token Support**
```python
# Process 1M+ tokens with linear memory complexity
attention = create_ring_attention(d_model=768, num_heads=12, max_sequence_length=1_000_000)
output = attention(million_token_sequence)  # Previously impossible on single GPU
```
- **Linear O(N) memory** vs quadratic O(N¬≤)
- **Distributed processing** across multiple GPUs
- **Production validated** for long documents, genomics, audio

#### **Dynamic Sparse Attention - 90% Compute Reduction**
```python
# Massive compute savings with minimal accuracy loss
attention = create_sparse_attention(d_model=512, num_heads=8, sparsity_ratio=0.9)
output = attention(x)  # 90% fewer computations, <1% accuracy loss
```
- **Content-aware patterns** adapt to input
- **Multiple strategies** from random to learned
- **Validated performance** across diverse workloads

#### **Context Parallel Attention - Multi-GPU Coordination**
```python
# Seamlessly distribute attention across multiple GPUs
attention = create_context_parallel_attention(d_model=512, num_heads=8, context_parallel_size=4)
output = attention(x)  # Automatically coordinated across 4 GPUs
```

### **‚ö° FP8 Training - 2x H100 Speedup**

#### **Production FP8 Training**
```python
# State-of-the-art FP8 training with automatic scaling
trainer = create_fp8_trainer(model, forward_format=FP8Format.E4M3, backward_format=FP8Format.E5M2)
with trainer:
    loss = trainer.training_step(inputs, targets)  # 2x speedup, 50% memory reduction
    success = trainer.optimizer_step(optimizer)   # Automatic overflow handling
```
- **E4M3/E5M2 formats** for optimal precision/range balance
- **Automatic scaling** prevents numerical instability
- **Production reliability** with overflow detection

#### **Model Conversion**
```python
# Convert any model to FP8
fp8_model = convert_model_to_fp8(existing_model)
# All linear layers automatically converted to FP8LinearLayer
```

### **üìê Dynamic Shape Bucketing**

#### **3x Variable Input Speedup**
```python
from kernel_pytorch.optimization_patterns import (
    DynamicShapeBucketing, DynamicShapeModule,
    BucketingStrategy, create_optimal_bucketing_system
)

# Create optimized bucketing for variable-size inputs
sample_inputs = [torch.randn(b, s, d) for b, s, d in variable_shapes]
bucketing = create_optimal_bucketing_system(
    sample_inputs,
    strategy=BucketingStrategy.HARDWARE_AWARE
)

# Wrap any model for automatic optimization
optimized_model = DynamicShapeModule(model, bucketing)
output = optimized_model(variable_input)  # 3x speedup, <10% memory overhead
```

#### **Key Features**
- **Hardware-aware bucketing** optimizes for GPU warp/tensor core alignment
- **Automatic padding strategies** minimize memory waste (<10% overhead)
- **Adaptive optimization** learns from input distributions over time
- **Thread-safe operation** for production multi-threaded environments

#### **Benchmarking & Analysis**
```python
# Run comprehensive benchmark comparing strategies
python demos/02_compiler_optimizations/dynamic_shapes_demo.py --compare-strategies

# Production benchmark suite
python benchmarks/dynamic_shapes_benchmark.py
```

### **üîß Hardware Abstraction Layer**

#### **Multi-Vendor GPU Support**
```python
# Unified optimization across hardware vendors
hal = HardwareAbstractionLayer()
optimized_model = hal.optimize_for_hardware(model)  # Auto-detects and optimizes
devices = detect_available_devices()               # NVIDIA, AMD, Intel support
```

## üìä Performance Results

### **Validated Speedups**
| Feature | Hardware | Speedup | Memory Reduction |
|---------|----------|---------|------------------|
| FP8 Training | H100 | **2.0x** | 50% |
| Dynamic Shape Bucketing | GPU | **3.0x** (variable inputs) | <10% overhead |
| Ring Attention | Any GPU | **Enables 1M+ tokens** | Linear O(N) |
| Sparse Attention | Any GPU | **10x** (90% sparsity) | Same |
| Context Parallel | Multi-GPU | **Linear scaling** | Distributed |

### **Hardware Compatibility**
| GPU Type | Performance Improvement | Notes |
|----------|------------------------|--------|
| NVIDIA H100/A100 | **1.5-2.0x** | Full FP8 + optimization |
| NVIDIA RTX 4090 | **1.3x** | Advanced attention |
| Intel Arc/AMD | **1.2x** | Hardware abstraction |
| CPU (Intel) | **1.15x** | Optimized fallbacks |

## üß™ Production Quality

### **Comprehensive Testing**
- ‚úÖ **185/216 tests passing** (31 skipped for GPU-only features)
- ‚úÖ **Statistical validation** with 95% confidence intervals
- ‚úÖ **Performance benchmarking** for regression detection
- ‚úÖ **Edge case coverage** including numerical stability

### **Working Demos**
- ‚úÖ **9/9 demos operational** with clear usage patterns
- ‚úÖ **Getting started** to **production deployment** examples
- ‚úÖ **Performance measurement** in all demos
- ‚úÖ **Cross-platform compatibility** (CPU/GPU)

### **Benchmark Framework**
- ‚úÖ **5 baseline implementations** for comparison
- ‚úÖ **Multi-vendor GPU testing** (NVIDIA, AMD, Intel)
- ‚úÖ **Memory profiling** and efficiency measurement
- ‚úÖ **Automated performance tracking**

## üìö Documentation

| Document | Purpose | Audience |
|----------|---------|----------|
| [README.md](./README.md) | Project overview & quick start | **All users** |
| [API.md](./API.md) | Complete API reference | **Developers** |
| [BENCHMARKS.md](./BENCHMARKS.md) | Performance validation | **Performance engineers** |
| [CONTRIBUTING.md](./CONTRIBUTING.md) | Development guide | **Contributors** |
| [CHANGELOG.md](./CHANGELOG.md) | Version history | **All users** |

## üõ†Ô∏è Development

### **Project Structure** (Phase 3 Optimized)
```
src/kernel_pytorch/
‚îú‚îÄ‚îÄ core/                  # Unified core optimization components (Phase 3)
‚îÇ   ‚îú‚îÄ‚îÄ compilers/        # Compiler integrations (FlashLight, PyGraph)
‚îÇ   ‚îú‚îÄ‚îÄ optimized_layers/ # Optimized layer implementations
‚îÇ   ‚îî‚îÄ‚îÄ components/       # Basic optimized components
‚îú‚îÄ‚îÄ optimizations/        # Unified optimization strategies (Phase 3)
‚îÇ   ‚îú‚îÄ‚îÄ patterns/        # Common optimization patterns
‚îÇ   ‚îî‚îÄ‚îÄ next_gen/        # Cutting-edge 2025+ techniques
‚îú‚îÄ‚îÄ hardware/            # Unified hardware optimization (Phase 3)
‚îÇ   ‚îú‚îÄ‚îÄ gpu/            # GPU-specific optimizations
‚îÇ   ‚îú‚îÄ‚îÄ abstraction/    # Hardware abstraction layer
‚îÇ   ‚îî‚îÄ‚îÄ kernels/        # CUDA kernels and interfaces
‚îú‚îÄ‚îÄ attention/           # Unified attention framework (Phase 2)
‚îú‚îÄ‚îÄ precision/           # FP8 training and quantization
‚îú‚îÄ‚îÄ mixture_of_experts/  # MoE implementations
‚îú‚îÄ‚îÄ advanced_memory/     # Memory optimizations
‚îú‚îÄ‚îÄ distributed_scale/   # Distributed computing
‚îú‚îÄ‚îÄ testing_framework/   # Validation and benchmarking
‚îî‚îÄ‚îÄ utils/              # Utility functions
```

### **Contributing**
1. **Setup**: `pip install -r requirements.txt`
2. **Test**: `PYTHONPATH=src python -m pytest tests/`
3. **Validate**: `python demos/run_all_demos.py --quick`
4. **Submit**: See [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed workflow

### **Code Quality**
- **PEP 8 compliant** naming conventions
- **Type hints** for IDE support
- **Comprehensive testing** for all features
- **Performance validation** for optimizations

## üéØ Use Cases

### **üî¨ Research**
- **Long sequence modeling** (genomics, audio, documents)
- **Large model training** with memory constraints
- **Multi-GPU coordination** for distributed workloads

### **üè≠ Production**
- **Model serving** with 2x speedup
- **Resource optimization** in cloud deployments
- **Hardware flexibility** across vendors

### **üìö Education**
- **PyTorch optimization** techniques
- **GPU programming** best practices
- **Performance engineering** methodologies

## üöÄ Next Steps

### **Phase 2 Roadmap (Next)**
- **FP4/MXFP Training**: Ultra-low precision with adaptive allocation
- **Structured Sparsity**: 2:4 patterns for Tensor Core acceleration
- **Hardware Kernels**: NVIDIA generation-specific optimization

### **Phase 3 Vision (Future)**
- **Neuromorphic Computing**: 100x energy efficiency
- **Quantum-Classical Hybrid**: Optimization acceleration
- **Post-Transformer Architectures**: Beyond attention mechanisms

## üìû Support

- **üìñ Documentation**: Complete API and usage guides available
- **üß™ Examples**: 9 production demos covering all features
- **üêõ Issues**: GitHub Issues for bug reports and feature requests
- **üí¨ Discussions**: Technical questions and community support

## üìÑ License

**Open source project - see LICENSE file for details.**

---

**Ready to accelerate your PyTorch models?** Start with the [demos](./demos/) for hands-on examples! ‚ö°
