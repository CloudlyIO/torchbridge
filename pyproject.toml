[build-system]
requires = ["setuptools>=61.0", "wheel", "pybind11>=2.10.0", "torch", "ninja"]
build-backend = "setuptools.build_meta"

[project]
name = "torchbridge-ml"
version = "0.5.7"
description = "Hardware abstraction layer for PyTorch across NVIDIA, AMD, Intel, and TPU backends"
authors = [{name = "TorchBridge Team"}]
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.10"
keywords = ["pytorch", "hardware-abstraction", "multi-backend", "cuda", "amd", "intel", "tpu", "machine-learning", "deep-learning"]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "torch>=2.0.0",
    "numpy>=1.21.0",
    "pybind11>=2.10.0",
]

[project.urls]
Homepage = "https://github.com/CloudlyIO/torchbridge"
Documentation = "https://torchbridge.readthedocs.io"
Repository = "https://github.com/CloudlyIO/torchbridge"
"Bug Tracker" = "https://github.com/CloudlyIO/torchbridge/issues"

[project.scripts]
torchbridge = "torchbridge.cli:main"
tb-optimize = "torchbridge.cli.optimize:main"
tb-benchmark = "torchbridge.cli.benchmark:main"
tb-export = "torchbridge.cli.export:main"
tb-profile = "torchbridge.cli.profile:main"
tb-doctor = "torchbridge.cli.doctor:main"
tb-init = "torchbridge.cli.init:main"
tb-validate = "torchbridge.cli.validate:main"
tb-migrate = "torchbridge.cli.migrate:main"

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "pytest-xdist>=3.0.0",
    "pytest-benchmark>=4.0.0",
    "matplotlib>=3.5.0",
    "seaborn>=0.11.0",
    "jupyter>=1.0.0",
    "tensorboard>=2.9.0",
    "ruff>=0.4.0",
    "mypy>=1.0.0",
    "pre-commit>=3.5.0",
    "bandit[toml]>=1.7.0",
]
all = [
    "transformers>=4.35.0",
    "datasets>=2.14.0",
    "tokenizers>=0.14.0",
    "triton>=2.1.0",
    "flash-attn>=2.3.0",
    "accelerate>=0.24.0",
]
cloud = [
    "boto3>=1.28.0",
    "google-cloud-storage>=2.10.0",
    "azure-storage-blob>=12.17.0",
    "kubernetes>=27.2.0",
]
serving = [
    "fastapi>=0.103.0",
    "uvicorn[standard]>=0.23.0",
    "torchserve>=0.8.0",
    "gradio>=3.45.0",
    "streamlit>=1.27.0",
]
monitoring = [
    "prometheus-client>=0.17.0",
    "wandb>=0.16.0",
    "tensorboard>=2.14.0",
    "mlflow>=2.7.0",
    "optuna>=3.4.0",
]
benchmark = [
    "memory-profiler>=0.61.0",
    "py-spy>=0.3.14",
    "torch-tb-profiler>=0.4.0",
    "psutil>=5.9.0",
    "gpustat>=1.1.0",
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-dir]
"" = "src"

[tool.ruff]
target-version = "py310"
line-length = 88
src = ["src", "tests"]

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "W",      # pycodestyle warnings
    "F",      # Pyflakes
    "I",      # isort
    "B",      # flake8-bugbear
    "C4",     # flake8-comprehensions
    "UP",     # pyupgrade
]
ignore = [
    "E501",   # Line length handled by formatter
    "B008",   # Do not perform function calls in argument defaults
    "B905",   # zip without strict
]

[tool.ruff.lint.per-file-ignores]
"src/torchbridge/__init__.py" = ["E402", "I001"]  # Warning suppression before imports is intentional
"src/torchbridge/cli/__init__.py" = ["E402", "I001"]  # Warning suppression before imports is intentional

[tool.ruff.lint.isort]
known-first-party = ["torchbridge"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.10"
warn_return_any = false
warn_unused_configs = true
ignore_missing_imports = true
disallow_untyped_defs = false
check_untyped_defs = false
no_implicit_optional = true
strict_equality = true
disable_error_code = [
    "assignment",
    "arg-type",
    "operator",
    "union-attr",
    "call-overload",
    "override",
    "var-annotated",
    "index",
    "misc",
    "has-type",
    "attr-defined",
    "dict-item",
    "return-value",
    "call-arg",
    "list-item",
    "type-var",
    "no-redef",
    "comparison-overlap",
    "abstract",
]
exclude = [
    "build",
    "dist",
    "\\.git",
    "__pycache__",
    "demos",
    "tests",
]

[[tool.mypy.overrides]]
module = [
    "torchbridge.utils.*",
    "torchbridge.precision.*",
    "torchbridge.mixture_of_experts.*",
    "torchbridge.hardware.gpu.*",
    "torchbridge.backends.*",
    "torchbridge.deployment.serving.*",
    "torchbridge.optimizations.*",
]
disallow_untyped_defs = false
warn_return_any = false

[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v --tb=short --strict-markers -ra"
markers = [
    "unit: Fast unit tests (< 1 second)",
    "integration: Integration tests (1-30 seconds)",
    "e2e: End-to-end tests (> 30 seconds)",
    "gpu: Requires CUDA GPU",
    "tpu: Requires TPU",
    "amd: Requires AMD GPU (ROCm)",
    "intel: Requires Intel GPU (XPU)",
    "fp8: Requires FP8 hardware (H100+)",
    "slow: Long-running tests",
    "benchmark: Performance benchmarks",
    "blackwell: Tests for NVIDIA Blackwell GPU support",
    "real_model: Tests that load real model weights from HuggingFace/torchvision",
    "requires_transformers: Requires HuggingFace transformers library",
    "requires_torchvision: Requires torchvision library",
]
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
]