============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-9.0.2, pluggy-1.6.0 -- /usr/bin/python3
cachedir: .pytest_cache
metadata: {'Python': '3.10.12', 'Platform': 'Linux-6.8.0-1045-gcp-x86_64-with-glibc2.35', 'Packages': {'pytest': '9.0.2', 'pluggy': '1.6.0'}, 'Plugins': {'metadata': '3.1.1', 'json-report': '1.5.0'}}
rootdir: /home/shahrahman
plugins: metadata-3.1.1, json-report-1.5.0
collecting ... collected 48 items

tests/test_moe.py::TestMoEConfig::test_config_creation PASSED            [  2%]
tests/test_moe.py::TestMoEConfig::test_config_customization PASSED       [  4%]
tests/test_moe.py::TestMoELayerCreation::test_standard_moe_creation PASSED [  6%]
tests/test_moe.py::TestMoELayerCreation::test_sparse_moe_creation PASSED [  8%]
tests/test_moe.py::TestMoELayerCreation::test_switch_transformer_creation PASSED [ 10%]
tests/test_moe.py::TestMoELayerCreation::test_glam_style_creation PASSED [ 12%]
tests/test_moe.py::TestMoELayerCreation::test_adaptive_moe_creation PASSED [ 14%]
tests/test_moe.py::TestMoELayerCreation::test_factory_function PASSED    [ 16%]
tests/test_moe.py::TestMoELayerCreation::test_create_moe_convenience PASSED [ 18%]
tests/test_moe.py::TestMoEForwardPass::test_standard_forward PASSED      [ 20%]
tests/test_moe.py::TestMoEForwardPass::test_forward_with_aux_losses PASSED [ 22%]
tests/test_moe.py::TestMoEForwardPass::test_sparse_forward PASSED        [ 25%]
tests/test_moe.py::TestMoEForwardPass::test_switch_forward PASSED        [ 27%]
tests/test_moe.py::TestMoEForwardPass::test_glam_forward PASSED          [ 29%]
tests/test_moe.py::TestMoEForwardPass::test_adaptive_forward PASSED      [ 31%]
tests/test_moe.py::TestRouters::test_topk_router PASSED                  [ 33%]
tests/test_moe.py::TestRouters::test_switch_router PASSED                [ 35%]
tests/test_moe.py::TestRouters::test_hash_router PASSED                  [ 37%]
tests/test_moe.py::TestRouters::test_dynamic_capacity_router PASSED      [ 39%]
tests/test_moe.py::TestExpertNetworks::test_feedforward_expert PASSED    [ 41%]
tests/test_moe.py::TestExpertNetworks::test_convolutional_expert PASSED  [ 43%]
tests/test_moe.py::TestExpertNetworks::test_attention_expert PASSED      [ 45%]
tests/test_moe.py::TestExpertNetworks::test_parameter_efficient_expert PASSED [ 47%]
tests/test_moe.py::TestLoadBalancing::test_load_balancer_creation PASSED [ 50%]
tests/test_moe.py::TestLoadBalancing::test_capacity_info PASSED          [ 52%]
tests/test_moe.py::TestLoadBalancing::test_load_balance_loss PASSED      [ 54%]
tests/test_moe.py::TestMoETraining::test_gradient_flow PASSED            [ 56%]
tests/test_moe.py::TestMoETraining::test_training_vs_eval PASSED         [ 58%]
tests/test_moe.py::TestMoETraining::test_expert_utilization_tracking PASSED [ 60%]
tests/test_moe.py::TestMoETraining::test_auxiliary_losses_gradient PASSED [ 62%]
tests/test_moe.py::TestExpertParallelism::test_parallelism_creation PASSED [ 64%]
tests/test_moe.py::TestMoEMemoryEfficiency::test_memory_efficient_switching PASSED [ 66%]
tests/test_moe.py::TestMoEMemoryEfficiency::test_expert_scheduler PASSED [ 68%]
tests/test_moe.py::TestMoEIntegration::test_moe_in_transformer PASSED    [ 70%]
tests/test_moe.py::TestMoEIntegration::test_moe_multiple_layers PASSED   [ 72%]
tests/test_moe.py::TestMoEIntegration::test_end_to_end_training PASSED   [ 75%]
tests/test_moe.py::test_moe_types[standard] PASSED                       [ 77%]
tests/test_moe.py::test_moe_types[sparse] PASSED                         [ 79%]
tests/test_moe.py::test_moe_types[switch] PASSED                         [ 81%]
tests/test_moe.py::test_moe_types[glam] PASSED                           [ 83%]
tests/test_moe.py::test_moe_types[adaptive] PASSED                       [ 85%]
tests/test_moe.py::test_different_expert_counts[2] PASSED                [ 87%]
tests/test_moe.py::test_different_expert_counts[4] PASSED                [ 89%]
tests/test_moe.py::test_different_expert_counts[8] PASSED                [ 91%]
tests/test_moe.py::test_different_expert_counts[16] PASSED               [ 93%]
tests/test_moe.py::test_different_top_k[1] PASSED                        [ 95%]
tests/test_moe.py::test_different_top_k[2] PASSED                        [ 97%]
tests/test_moe.py::test_different_top_k[4] PASSED                        [100%]

=============================== warnings summary ===============================
kernel_pytorch/attention/distributed/ring_attention.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/ring_attention.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/attention/distributed/context_parallel.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/context_parallel.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/precision/fp8_training_engine.py:34
  /home/shahrahman/kernel_pytorch/precision/fp8_training_engine.py:34: UserWarning: Transformer Engine not available - FP8 training will use fallback implementations
    warnings.warn("Transformer Engine not available - FP8 training will use fallback implementations")

kernel_pytorch/distributed_scale/__init__.py:28
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:28: FutureWarning: communication_optimization.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: communication_primitives, network_optimization, communication_profiling
    from .communication_optimization import (

kernel_pytorch/distributed_scale/__init__.py:35
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:35: FutureWarning: hardware_adaptation.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: hardware_discovery, thermal_power_management, fault_tolerance, hardware_adapter
    from .hardware_adaptation import (

kernel_pytorch/distributed_scale/__init__.py:42
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:42: FutureWarning: orchestration.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: job_management, cluster_management, scaling_fault_tolerance
    from .orchestration import (

kernel_pytorch/hardware/__init__.py:28
  /home/shahrahman/kernel_pytorch/hardware/__init__.py:28: UserWarning: Hardware abstraction import failed: No module named 'kernel_pytorch.hardware.distributed_scale'
    warnings.warn(f"Hardware abstraction import failed: {e}")

kernel_pytorch/precision/fp8_optimizations.py:32
  /home/shahrahman/kernel_pytorch/precision/fp8_optimizations.py:32: UserWarning: Transformer Engine not available - using fallback FP8 implementations
    warnings.warn("Transformer Engine not available - using fallback FP8 implementations")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 48 passed, 8 warnings in 6.76s ========================
