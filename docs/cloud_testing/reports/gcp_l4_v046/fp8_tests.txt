============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-9.0.2, pluggy-1.6.0 -- /usr/bin/python3
cachedir: .pytest_cache
metadata: {'Python': '3.10.12', 'Platform': 'Linux-6.8.0-1045-gcp-x86_64-with-glibc2.35', 'Packages': {'pytest': '9.0.2', 'pluggy': '1.6.0'}, 'Plugins': {'metadata': '3.1.1', 'json-report': '1.5.0'}}
rootdir: /home/shahrahman
plugins: metadata-3.1.1, json-report-1.5.0
collecting ... collected 71 items

tests/test_fp8_native.py::TestFP8Availability::test_is_fp8_available PASSED [  1%]
tests/test_fp8_native.py::TestFP8Availability::test_get_fp8_info PASSED  [  2%]
tests/test_fp8_native.py::TestFP8Availability::test_fp8_dtype_enum PASSED [  4%]
tests/test_fp8_native.py::TestFP8Availability::test_get_fp8_dtype PASSED [  5%]
tests/test_fp8_native.py::TestFP8Quantization::test_compute_fp8_scale_e4m3 PASSED [  7%]
tests/test_fp8_native.py::TestFP8Quantization::test_compute_fp8_scale_e5m2 PASSED [  8%]
tests/test_fp8_native.py::TestFP8Quantization::test_compute_fp8_scale_with_margin PASSED [  9%]
tests/test_fp8_native.py::TestFP8Quantization::test_quantize_to_fp8_e4m3 PASSED [ 11%]
tests/test_fp8_native.py::TestFP8Quantization::test_quantize_to_fp8_e5m2 PASSED [ 12%]
tests/test_fp8_native.py::TestFP8Quantization::test_dequantize_from_fp8 PASSED [ 14%]
tests/test_fp8_native.py::TestFP8Quantization::test_roundtrip_accuracy PASSED [ 15%]
tests/test_fp8_native.py::TestFP8Quantization::test_e4m3_vs_e5m2_precision PASSED [ 16%]
tests/test_fp8_native.py::TestFP8QuantizedTensor::test_from_tensor PASSED [ 18%]
tests/test_fp8_native.py::TestFP8QuantizedTensor::test_dequantize PASSED [ 19%]
tests/test_fp8_native.py::TestFP8QuantizedTensor::test_to_device PASSED  [ 21%]
tests/test_fp8_native.py::TestFP8QuantizedTensor::test_with_custom_scale PASSED [ 22%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_creation PASSED [ 23%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_creation_no_bias PASSED [ 25%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_forward PASSED [ 26%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_forward_batch PASSED [ 28%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_gradient_flow PASSED [ 29%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_weight_formats PASSED [ 30%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_get_fp8_info PASSED [ 32%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_sync_weights PASSED [ 33%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_training_mode PASSED [ 35%]
tests/test_fp8_native.py::TestNativeFP8Linear::test_layer_eval_mode PASSED [ 36%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_creation PASSED [ 38%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_prepare PASSED [ 39%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_infer PASSED [ 40%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_infer_not_prepared PASSED [ 42%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_memory_savings PASSED [ 43%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_layer_info PASSED [ 45%]
tests/test_fp8_native.py::TestFP8InferenceEngine::test_engine_with_calibration PASSED [ 46%]
tests/test_fp8_native.py::TestModelConversion::test_convert_model PASSED [ 47%]
tests/test_fp8_native.py::TestModelConversion::test_convert_model_inplace PASSED [ 49%]
tests/test_fp8_native.py::TestModelConversion::test_convert_model_not_inplace PASSED [ 50%]
tests/test_fp8_native.py::TestModelConversion::test_converted_model_forward PASSED [ 52%]
tests/test_fp8_native.py::TestModelConversion::test_converted_model_backward PASSED [ 53%]
tests/test_fp8_native.py::TestNumericalStability::test_large_values PASSED [ 54%]
tests/test_fp8_native.py::TestNumericalStability::test_small_values PASSED [ 56%]
tests/test_fp8_native.py::TestNumericalStability::test_mixed_range PASSED [ 57%]
tests/test_fp8_native.py::TestNumericalStability::test_fp8_linear_numerical_stability PASSED [ 59%]
tests/test_fp8_native.py::TestBenchmark::test_benchmark_fp8_layer PASSED [ 60%]
tests/test_fp8_native.py::TestIntegration::test_end_to_end_training PASSED [ 61%]
tests/test_fp8_native.py::TestIntegration::test_fp8_with_standard_layers PASSED [ 63%]
tests/test_fp8_native.py::test_quantization_formats[FP8Dtype.E4M3] PASSED [ 64%]
tests/test_fp8_native.py::test_quantization_formats[FP8Dtype.E5M2] PASSED [ 66%]
tests/test_fp8_native.py::test_layer_sizes[64-64] PASSED                 [ 67%]
tests/test_fp8_native.py::test_layer_sizes[256-128] PASSED               [ 69%]
tests/test_fp8_native.py::test_layer_sizes[512-512] PASSED               [ 70%]
tests/test_fp8_native.py::test_layer_sizes[1024-256] PASSED              [ 71%]
tests/test_fp8_training.py::TestFP8Config::test_config_creation PASSED   [ 73%]
tests/test_fp8_training.py::TestFP8Config::test_config_validation PASSED [ 74%]
tests/test_fp8_training.py::TestFP8LinearLayer::test_layer_creation PASSED [ 76%]
tests/test_fp8_training.py::TestFP8LinearLayer::test_forward_pass PASSED [ 77%]
tests/test_fp8_training.py::TestFP8LinearLayer::test_scale_updates PASSED [ 78%]
tests/test_fp8_training.py::TestFP8TrainingEngine::test_engine_creation PASSED [ 80%]
tests/test_fp8_training.py::TestFP8TrainingEngine::test_setup_fp8_training PASSED [ 81%]
tests/test_fp8_training.py::TestFP8TrainingEngine::test_training_step PASSED [ 83%]
tests/test_fp8_training.py::TestFP8TrainingEngine::test_optimizer_step PASSED [ 84%]
tests/test_fp8_training.py::TestFP8TrainingEngine::test_context_manager PASSED [ 85%]
tests/test_fp8_training.py::TestFP8ModelConversion::test_convert_model PASSED [ 87%]
tests/test_fp8_training.py::TestFP8ModelConversion::test_converted_model_forward PASSED [ 88%]
tests/test_fp8_training.py::TestFP8Validation::test_validate_fp8_setup PASSED [ 90%]
tests/test_fp8_training.py::TestFP8Integration::test_factory_function PASSED [ 91%]
tests/test_fp8_training.py::TestFP8Integration::test_end_to_end_training PASSED [ 92%]
tests/test_fp8_training.py::TestFP8Integration::test_statistics_tracking PASSED [ 94%]
tests/test_fp8_training.py::TestFP8Performance::test_memory_efficiency PASSED [ 95%]
tests/test_fp8_training.py::TestFP8Performance::test_numerical_stability PASSED [ 97%]
tests/test_fp8_training.py::test_different_format_combinations[format_combo0] PASSED [ 98%]
tests/test_fp8_training.py::test_different_format_combinations[format_combo1] PASSED [100%]

=============================== warnings summary ===============================
kernel_pytorch/attention/distributed/ring_attention.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/ring_attention.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/attention/distributed/context_parallel.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/context_parallel.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/precision/fp8_training_engine.py:34
  /home/shahrahman/kernel_pytorch/precision/fp8_training_engine.py:34: UserWarning: Transformer Engine not available - FP8 training will use fallback implementations
    warnings.warn("Transformer Engine not available - FP8 training will use fallback implementations")

kernel_pytorch/distributed_scale/__init__.py:28
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:28: FutureWarning: communication_optimization.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: communication_primitives, network_optimization, communication_profiling
    from .communication_optimization import (

kernel_pytorch/distributed_scale/__init__.py:35
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:35: FutureWarning: hardware_adaptation.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: hardware_discovery, thermal_power_management, fault_tolerance, hardware_adapter
    from .hardware_adaptation import (

kernel_pytorch/distributed_scale/__init__.py:42
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:42: FutureWarning: orchestration.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: job_management, cluster_management, scaling_fault_tolerance
    from .orchestration import (

kernel_pytorch/hardware/__init__.py:28
  /home/shahrahman/kernel_pytorch/hardware/__init__.py:28: UserWarning: Hardware abstraction import failed: No module named 'kernel_pytorch.hardware.distributed_scale'
    warnings.warn(f"Hardware abstraction import failed: {e}")

kernel_pytorch/precision/fp8_optimizations.py:32
  /home/shahrahman/kernel_pytorch/precision/fp8_optimizations.py:32: UserWarning: Transformer Engine not available - using fallback FP8 implementations
    warnings.warn("Transformer Engine not available - using fallback FP8 implementations")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 71 passed, 8 warnings in 5.38s ========================
