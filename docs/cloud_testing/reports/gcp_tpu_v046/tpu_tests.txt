SSH key found in project metadata; not updating instance.
Using ssh batch size of 1. Attempting to SSH into 1 nodes with a total of 1 workers.
SSH: Attempting to connect to worker 0...
============================= test session starts ==============================
platform linux -- Python 3.10.6, pytest-9.0.2, pluggy-1.6.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /home/shahrahman
collecting ... collected 79 items

tests/test_tpu_config.py::TestTPUConfig::test_tpu_config_creation PASSED [  1%]
tests/test_tpu_config.py::TestTPUConfig::test_tpu_config_custom_values PASSED [  2%]
tests/test_tpu_config.py::TestTPUConfig::test_tpu_config_serialization PASSED [  3%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_version_v4 PASSED [  5%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_version_v5p PASSED [  6%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_topology_single PASSED [  7%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_topology_pod PASSED [  8%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_version_no_xla PASSED [ 10%]
tests/test_tpu_config.py::TestTPUConfig::test_detect_tpu_topology_no_xla PASSED [ 11%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_config_with_tpu_backend PASSED [ 12%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_config_tpu_serialization PASSED [ 13%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_device_detection_tpu_available PASSED [ 15%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_device_detection_no_tpu PASSED [ 16%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_tpu_config_modes PASSED [ 17%]
tests/test_tpu_config.py::TestKernelPyTorchConfigTPU::test_tpu_hardware_backend_enum PASSED [ 18%]
tests/test_tpu_config.py::TestTPUEnums::test_tpu_version_enum PASSED     [ 20%]
tests/test_tpu_config.py::TestTPUEnums::test_tpu_topology_enum PASSED    [ 21%]
tests/test_tpu_config.py::TestTPUEnums::test_tpu_compilation_mode_enum PASSED [ 22%]
tests/test_tpu_config.py::TestTPUConfigValidation::test_valid_tpu_configs PASSED [ 24%]
tests/test_tpu_config.py::TestTPUConfigValidation::test_tpu_config_memory_bounds PASSED [ 25%]
tests/test_tpu_config.py::TestTPUConfigValidation::test_tpu_config_xla_optimization_levels PASSED [ 26%]
tests/test_tpu_config.py::TestTPUConfigValidation::test_tpu_config_precision_values PASSED [ 27%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_creation PASSED [ 29%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_model_preparation PASSED [ 30%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_data_preparation PASSED [ 31%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_memory_stats PASSED [ 32%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_synchronization PASSED [ 34%]
tests/test_tpu_backend.py::TestTPUBackend::test_tpu_backend_cache_management PASSED [ 35%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_creation PASSED [ 36%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_conservative_optimization PASSED [ 37%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_balanced_optimization PASSED [ 39%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_aggressive_optimization PASSED [ 40%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_inference_optimization FAILED [ 41%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_training_optimization PASSED [ 43%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_stats PASSED [ 44%]
tests/test_tpu_backend.py::TestTPUOptimizer::test_invalid_optimization_level PASSED [ 45%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_creation PASSED [ 46%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_model_compilation PASSED [ 48%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_inference_optimization PASSED [ 49%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_training_optimization PASSED [ 50%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_stats PASSED [ 51%]
tests/test_tpu_backend.py::TestXLACompiler::test_xla_compiler_benchmark PASSED [ 53%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_memory_manager_creation PASSED [ 54%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_tensor_allocation PASSED [ 55%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_tensor_layout_optimization PASSED [ 56%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_memory_pool_creation PASSED [ 58%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_memory_pool_operations PASSED [ 59%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_memory_stats PASSED [ 60%]
tests/test_tpu_backend.py::TestTPUMemoryManager::test_memory_optimization PASSED [ 62%]
tests/test_tpu_backend.py::TestXLAIntegration::test_xla_device_manager PASSED [ 63%]
tests/test_tpu_backend.py::TestXLAIntegration::test_xla_distributed_training PASSED [ 64%]
tests/test_tpu_backend.py::TestXLAIntegration::test_xla_optimizations PASSED [ 65%]
tests/test_tpu_backend.py::TestXLAIntegration::test_xla_utilities PASSED [ 67%]
tests/test_tpu_backend.py::TestXLAIntegration::test_create_xla_integration PASSED [ 68%]
tests/test_tpu_backend.py::TestTPUValidation::test_tpu_configuration_validation PASSED [ 69%]
tests/test_tpu_backend.py::TestTPUValidation::test_tpu_model_validation PASSED [ 70%]
tests/test_tpu_backend.py::TestTPUValidation::test_tpu_validation_with_warnings PASSED [ 72%]
tests/test_tpu_backend.py::TestTPUConfigurationModes::test_inference_mode_tpu PASSED [ 73%]
tests/test_tpu_backend.py::TestTPUConfigurationModes::test_training_mode_tpu PASSED [ 74%]
tests/test_tpu_backend.py::TestTPUConfigurationModes::test_development_mode_tpu PASSED [ 75%]
tests/test_tpu_backend.py::TestTPUConfigurationModes::test_tpu_config_serialization_modes PASSED [ 77%]
tests/test_tpu_backend.py::TestTPUErrorHandling::test_invalid_tpu_version PASSED [ 78%]
tests/test_tpu_backend.py::TestTPUErrorHandling::test_invalid_memory_fraction PASSED [ 79%]
tests/test_tpu_backend.py::TestTPUErrorHandling::test_missing_sample_inputs PASSED [ 81%]
tests/test_tpu_backend.py::TestTPUErrorHandling::test_backend_without_xla FAILED [ 82%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_lru_cache_eviction PASSED [ 83%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_compilation_cache_limits PASSED [ 84%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_strict_validation_mode PASSED [ 86%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_custom_exceptions_importable PASSED [ 87%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_memory_stats_with_retention PASSED [ 88%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_configurable_tpu_memory_capacity PASSED [ 89%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_cache_utils_statistics PASSED [ 91%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_cache_eviction_behavior PASSED [ 92%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_optimizer_with_invalid_level PASSED [ 93%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_memory_pool_operations PASSED [ 94%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_compilation_mode_configuration PASSED [ 96%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_logging_not_print PASSED [ 97%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_xla_optimization_levels PASSED [ 98%]
tests/test_tpu_backend.py::TestTPUErrorPaths::test_cache_clear_operations PASSED [100%]

=================================== FAILURES ===================================
__________ TestTPUOptimizer.test_tpu_optimizer_inference_optimization __________

self = <test_tpu_backend.TestTPUOptimizer object at 0x7f89c6751840>

    def test_tpu_optimizer_inference_optimization(self):
        """Test inference-specific optimization."""
        config = KernelPyTorchConfig()
        optimizer = TPUOptimizer(config)
    
        model = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 10))
        sample_input = torch.randn(8, 64)
    
        result = optimizer.optimize_for_inference(model, sample_input)
    
        assert result is not None
        assert result.optimized_model is not None
>       assert not result.optimized_model.training  # Should be in eval mode
E       AttributeError: 'function' object has no attribute 'training'

tests/test_tpu_backend.py:174: AttributeError
________________ TestTPUErrorHandling.test_backend_without_xla _________________

self = <test_tpu_backend.TestTPUErrorHandling object at 0x7f89c672bc40>

    def test_backend_without_xla(self):
        """Test backend operations without XLA available."""
        config = KernelPyTorchConfig()
        backend = TPUBackend(config)
    
        # Should work with CPU fallback
>       assert backend.device.type == 'cpu'
E       AssertionError: assert 'xla' == 'cpu'
E         
E         - cpu
E         + xla

tests/test_tpu_backend.py:517: AssertionError
=============================== warnings summary ===============================
kernel_pytorch/attention/distributed/ring_attention.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/ring_attention.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/attention/distributed/context_parallel.py:41
  /home/shahrahman/kernel_pytorch/attention/distributed/context_parallel.py:41: UserWarning: Hardware Abstraction Layer not available - using basic device coordination
    warnings.warn("Hardware Abstraction Layer not available - using basic device coordination")

kernel_pytorch/precision/fp8_training_engine.py:34
  /home/shahrahman/kernel_pytorch/precision/fp8_training_engine.py:34: UserWarning: Transformer Engine not available - FP8 training will use fallback implementations
    warnings.warn("Transformer Engine not available - FP8 training will use fallback implementations")

kernel_pytorch/distributed_scale/__init__.py:28
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:28: FutureWarning: communication_optimization.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: communication_primitives, network_optimization, communication_profiling
    from .communication_optimization import (

kernel_pytorch/distributed_scale/__init__.py:35
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:35: FutureWarning: hardware_adaptation.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: hardware_discovery, thermal_power_management, fault_tolerance, hardware_adapter
    from .hardware_adaptation import (

kernel_pytorch/distributed_scale/__init__.py:42
  /home/shahrahman/kernel_pytorch/distributed_scale/__init__.py:42: FutureWarning: orchestration.py has been refactored into multiple focused modules. Consider importing from the specific modules directly: job_management, cluster_management, scaling_fault_tolerance
    from .orchestration import (

kernel_pytorch/hardware/__init__.py:28
  /home/shahrahman/kernel_pytorch/hardware/__init__.py:28: UserWarning: Hardware abstraction import failed: No module named 'kernel_pytorch.hardware.distributed_scale'
    warnings.warn(f"Hardware abstraction import failed: {e}")

kernel_pytorch/precision/fp8_optimizations.py:32
  /home/shahrahman/kernel_pytorch/precision/fp8_optimizations.py:32: UserWarning: Transformer Engine not available - using fallback FP8 implementations
    warnings.warn("Transformer Engine not available - using fallback FP8 implementations")

tests/test_tpu_backend.py::TestXLAIntegration::test_xla_optimizations
  /home/shahrahman/kernel_pytorch/backends/tpu/xla_integration.py:306: UserWarning: Linear layer 2 dimensions (32x10) not optimal for TPU. Consider padding to multiples of 8.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_tpu_backend.py::TestTPUOptimizer::test_tpu_optimizer_inference_optimization
FAILED tests/test_tpu_backend.py::TestTPUErrorHandling::test_backend_without_xla
=================== 2 failed, 77 passed, 9 warnings in 6.45s ===================
