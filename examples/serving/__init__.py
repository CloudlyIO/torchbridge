"""
Serving Examples for KernelPyTorch

This package contains examples demonstrating how to serve models
in production using KernelPyTorch's deployment features.

Available examples:
- run_llm_server.py: LLM inference server with streaming and batching

Version: 0.4.22
"""
